{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trafficSignRecog.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Traffic Sign Recognition Modeling**"
      ],
      "metadata": {
        "id": "QRyR8Bzt_Z2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing all necessary libraries\n"
      ],
      "metadata": {
        "id": "xk9iwsDC_tI-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjouqgDs_WaI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing The Dataset"
      ],
      "metadata": {
        "id": "9tLm_eWm_zCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "classes = 43\n",
        "cur_path = os.getcwd() #returns current working directory of a process\n",
        "#Retrieving the images and their labels \n",
        "for i in range(classes):\n",
        " path = os.path.join(cur_path,'train',str(i)) #joins one or more path componen\n",
        " images = os.listdir(path) #lists files and directories in \n",
        " for a in images: \n",
        " try:\n",
        " image = Image.open(path + '/'+ a) #opens image file \n",
        " image = image.resize((30,30)) #sizing the opened image\n",
        " image = np.array(image) #array of images\n",
        " #sim = Image.fromarray(image) \n",
        " data.append(image) #appending the data list\n",
        " labels.append(i) #appending the labels list\n",
        " except:\n",
        " print(\"Error loading image\")\n"
      ],
      "metadata": {
        "id": "EFOZcEiQ_2KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting Lists Into Numpy Arrays"
      ],
      "metadata": {
        "id": "CLuhL8tR_472"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting lists into numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "print(data.shape, labels.shape)\n"
      ],
      "metadata": {
        "id": "sqT4_D4d_8fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting training and testing dataset"
      ],
      "metadata": {
        "id": "dCtjVtS3AI4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, ra\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "PThfSIfWAKkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the labels into one hot encoding"
      ],
      "metadata": {
        "id": "pbOsq5wPAMxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the labels into one hot encoding\n",
        "y_train = to_categorical(y_train, 43)\n",
        "y_test = to_categorical(y_test, 43)"
      ],
      "metadata": {
        "id": "DUsxTnwpAPwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model"
      ],
      "metadata": {
        "id": "iyKQEvVPARGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_tr\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.3))\n",
        "model.add(Flatten()) #convert nD array t\n",
        "model.add(Dense(190, activation='relu')) \n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(43, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "T45EP9wlARoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilation of the Model"
      ],
      "metadata": {
        "id": "ztuOcDQIAT8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compilation of the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy\n",
        "epochs = 12\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data\n",
        "model.save(\"my_model.h5\")\n"
      ],
      "metadata": {
        "id": "CLFTFuP8AZBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Graphs for Accuracy"
      ],
      "metadata": {
        "id": "WOgq7omHAb_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting graphs for accuracy \n",
        "plt.figure(0)\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#An epoch is the number of times the iteration takes place to fit the model.\n",
        "#with more epochs, the accuracy increases\n",
        "#validation set is used to validate the model's performance\n",
        "#dropout is the amount of units ignored randomly from the dataset.\n"
      ],
      "metadata": {
        "id": "OuE_nd4OAdqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing Accuracy on Test Dataset\n"
      ],
      "metadata": {
        "id": "LOmu0x1FAiea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testing accuracy on test dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_test = pd.read_csv('Test.csv')\n",
        "labels = y_test[\"ClassId\"].values\n",
        "imgs = y_test[\"Path\"].values\n",
        "data=[]\n",
        "for img in imgs:\n",
        " image = Image.open(img)\n",
        " image = image.resize((30,30))\n",
        " data.append(np.array(image))\n",
        "X_test=np.array(data) #creating numpy array of test data of images\n",
        "pred = model.predict_classes(X_test) #predicting the classes for test dataset"
      ],
      "metadata": {
        "id": "8CIghedTAk1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy with the Test Data\n"
      ],
      "metadata": {
        "id": "XAnjgDanAsDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy with the test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels, pred)) #finding accuracy for the test data \n",
        "model.save(\"traffic_classifier.h5\") \n"
      ],
      "metadata": {
        "id": "Y2IH_wdrAmjG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}